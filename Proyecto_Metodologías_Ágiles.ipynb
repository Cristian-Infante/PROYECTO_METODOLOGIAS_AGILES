{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOpS99XjIRZl",
    "outputId": "14203844-00ec-41d0-f249-8656e9691bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sodapy in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: requests>=2.28.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sodapy) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.1->sodapy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.1->sodapy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.1->sodapy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.1->sodapy) (2025.10.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: altair in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from altair) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from altair) (4.15.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair) (0.28.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydeck in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: jinja2>=2.10.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydeck) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydeck) (2.3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2>=2.10.1->pydeck) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.50.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.3.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.33.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (22.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josehp\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "up to date, audited 23 packages in 978ms\n",
      "\n",
      "3 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "2 high severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 41.0/60.8 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.9 MB 9.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.8/8.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/8.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 14.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.0/8.9 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.9/8.9 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB ? eta 0:00:00\n",
      "Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.4/38.7 MB 93.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 9.7/38.7 MB 103.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.6/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.5/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 72.5 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\josehp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 41.0/60.8 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.9 MB 9.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.8/8.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/8.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 14.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.0/8.9 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.9/8.9 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB ? eta 0:00:00\n",
      "Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.4/38.7 MB 93.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 9.7/38.7 MB 103.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.6/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.5/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/38.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 72.5 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# make sure to install these packages before running:\n",
    "!pip install pandas\n",
    "!pip install sodapy\n",
    "!pip install altair\n",
    "!pip install pydeck\n",
    "!pip install streamlit\n",
    "!npm i localtunnel\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsCVzdOFW1tE",
    "outputId": "6095bdab-5ef1-439b-d4d5-8a22717b21fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n",
      "C:\\Users\\Josehp\\AppData\\Local\\Temp\\ipykernel_25392\\2787591777.py:41: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"fecha_actualizacion\"] = pd.to_datetime(df[\"fecha_de_actualizaci_n\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet generado: data/suit_tramites.parquet  (535,926 filas)\n"
     ]
    }
   ],
   "source": [
    "# preprocess_suit.py\n",
    "# Descarga un subconjunto de SUIT y lo guarda en Parquet.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "# ---------- Configuración ----------\n",
    "DOMAIN     = \"www.datos.gov.co\"\n",
    "DATASET_ID = \"48fq-mxnm\"\n",
    "LIMIT      = 536_000                          # filas a descargar\n",
    "OUT_PATH   = \"data/suit_tramites.parquet\"\n",
    "\n",
    "SELECT_COLUMNS = [\n",
    "    \"fecha_de_actualizaci_n\",\n",
    "    \"departamento\",\n",
    "    \"municipio\",\n",
    "    \"nombre_de_la_entidad\",\n",
    "    \"latitud_municipio\",\n",
    "    \"longitud_municipio\",\n",
    "]\n",
    "\n",
    "def _to_num(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s.str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "def main() -> None:\n",
    "    os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "\n",
    "    client = Socrata(DOMAIN, None)          # público, sin token\n",
    "    raw = client.get(DATASET_ID,\n",
    "                     select=\", \".join(SELECT_COLUMNS),\n",
    "                     limit=LIMIT)\n",
    "    client.close()\n",
    "\n",
    "    df = pd.DataFrame.from_records(raw)\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"No se obtuvieron registros.\")\n",
    "\n",
    "    # --- Limpieza mínima ---\n",
    "    df = df.rename(columns={\"nombre_de_la_entidad\": \"entidad\"})\n",
    "    df[\"fecha_actualizacion\"] = pd.to_datetime(df[\"fecha_de_actualizaci_n\"], errors=\"coerce\")\n",
    "\n",
    "    fa = df[\"fecha_actualizacion\"]\n",
    "    df[\"anio\"]      = fa.dt.year.astype(\"Int64\")\n",
    "    df[\"mes_num\"]   = fa.dt.month.astype(\"Int64\")\n",
    "    df[\"fecha_mes\"] = fa.dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "    df[\"lat\"] = _to_num(df[\"latitud_municipio\"].astype(str))\n",
    "    df[\"lon\"] = _to_num(df[\"longitud_municipio\"].astype(str))\n",
    "    df[\"coords_validas\"] = df[\"lat\"].between(-90, 90) & df[\"lon\"].between(-180, 180)\n",
    "\n",
    "    df.to_parquet(OUT_PATH, index=False)\n",
    "    print(f\"Parquet generado: {OUT_PATH}  ({len(df):,} filas)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEUxcw8sXKMj",
    "outputId": "daa4c054-0fa2-45c6-b45c-e565b0256f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dashboard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dashboard.py\n",
    "# Streamlit — carga Parquet preprocesado y visualiza.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import pydeck as pdk\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from components.kpis import render_kpi_cards, KpiValues\n",
    "\n",
    "# ---------- Config ----------\n",
    "st.set_page_config(page_title=\"Trámites Visibles\", layout=\"wide\")\n",
    "PARQUET_PATH = \"data/suit_tramites.parquet\"\n",
    "\n",
    "@st.cache_data(ttl=3600, show_spinner=True)\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "if not os.path.exists(PARQUET_PATH):\n",
    "    st.error(\"No se encontró el Parquet. Ejecuta `python preprocess_suit.py`.\")\n",
    "    st.stop()\n",
    "\n",
    "df = load_data(PARQUET_PATH)\n",
    "if df.empty:\n",
    "    st.warning(\"El Parquet está vacío.\")\n",
    "    st.stop()\n",
    "\n",
    "st.title(\"Trámites Visibles\")\n",
    "st.caption(\"Serie mensual por año (superpuesta). Base: fecha de actualización.\")\n",
    "\n",
    "# ---------- util ----------\n",
    "MESES_MAP = {1:\"Ene\",2:\"Feb\",3:\"Mar\",4:\"Abr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Ago\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dic\"}\n",
    "MESES_ORD = list(range(1,13))\n",
    "\n",
    "def detect_peaks(series: pd.Series, threshold: float = 1.5) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Detecta picos/anomalías usando desviación estándar.\n",
    "    \n",
    "    Args:\n",
    "        series: Serie de datos numéricos (trámites)\n",
    "        threshold: Multiplicador de desv. estándar (1.5 = moderado, 2.0 = estricto)\n",
    "    \n",
    "    Returns:\n",
    "        Serie booleana: True donde hay anomalía\n",
    "    \"\"\"\n",
    "    if series.empty or series.std() == 0:\n",
    "        return pd.Series(False, index=series.index)\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    return (series - mean).abs() > (threshold * std)\n",
    "\n",
    "def pct_change_between_two_years(d: pd.DataFrame, y0: int, y1: int, months: list[int]) -> float | None:\n",
    "    \"\"\"Variación % entre y0 (base) y y1 (comparado) usando SOLO meses presentes en ambos años.\"\"\"\n",
    "    if d.empty or y0 is None or y1 is None or y0 == y1:\n",
    "        return None\n",
    "    months = list(months) if months else MESES_ORD\n",
    "    m0 = set(d.loc[d[\"anio\"] == y0, \"mes_num\"].dropna().astype(int)) & set(months)\n",
    "    m1 = set(d.loc[d[\"anio\"] == y1, \"mes_num\"].dropna().astype(int)) & set(months)\n",
    "    inter = sorted(m0 & m1)\n",
    "    if not inter:\n",
    "        return None\n",
    "    a = len(d[(d[\"anio\"] == y1) & (d[\"mes_num\"].isin(inter))])\n",
    "    b = len(d[(d[\"anio\"] == y0) & (d[\"mes_num\"].isin(inter))])\n",
    "    if b == 0:\n",
    "        return None\n",
    "    return (a - b) / b * 100.0\n",
    "\n",
    "# ---------- Sidebar (filtros dependientes) ----------\n",
    "with st.sidebar:\n",
    "    st.header(\"Filtros\")\n",
    "\n",
    "    # 1) Años\n",
    "    anios_all = sorted(df[\"anio\"].dropna().unique().astype(int).tolist())\n",
    "    anios_sel = st.multiselect(\"Años\", options=anios_all, default=anios_all, key=\"f_anios\")\n",
    "    df1 = df[df[\"anio\"].isin(anios_sel)] if anios_sel else df.copy()\n",
    "\n",
    "    # 2) Meses (derivados de años)\n",
    "    meses_opts = sorted(df1[\"mes_num\"].dropna().unique().astype(int).tolist()) or MESES_ORD\n",
    "    meses_sel = st.multiselect(\"Meses\", options=meses_opts, default=meses_opts,\n",
    "                               format_func=lambda m: MESES_MAP.get(m, str(m)), key=\"f_meses\")\n",
    "    df2 = df1[df1[\"mes_num\"].isin(meses_sel)] if meses_sel else df1.copy()\n",
    "\n",
    "    # 3) Departamento\n",
    "    deptos_opts = sorted(df2[\"departamento\"].dropna().unique().tolist())\n",
    "    d_sel = st.multiselect(\"Departamento\", options=deptos_opts, default=[], key=\"f_depto\")\n",
    "    df3 = df2[df2[\"departamento\"].isin(d_sel)] if d_sel else df2.copy()\n",
    "\n",
    "    # 4) Municipio\n",
    "    municipios_opts = sorted(df3[\"municipio\"].dropna().unique().tolist())\n",
    "    mpio_sel = st.multiselect(\"Municipio\", options=municipios_opts, default=[], key=\"f_mpio\")\n",
    "    df4 = df3[df3[\"municipio\"].isin(mpio_sel)] if mpio_sel else df3.copy()\n",
    "\n",
    "    # 5) Entidad\n",
    "    entidades_opts = sorted(df4[\"entidad\"].dropna().unique().tolist())\n",
    "    entidades_opts = entidades_opts[:300] if len(entidades_opts) > 300 else entidades_opts\n",
    "    e_sel = st.multiselect(\"Entidad\", options=entidades_opts, default=[], key=\"f_entidad\")\n",
    "    df_f = df4[df4[\"entidad\"].isin(e_sel)] if e_sel else df4.copy()\n",
    "\n",
    "    # --- Controles de análisis visual ---\n",
    "    st.divider()\n",
    "    st.subheader(\"Análisis Visual\")\n",
    "    mostrar_tendencia = st.checkbox(\"Línea de tendencia\", value=False, key=\"toggle_tendencia\")\n",
    "    mostrar_anomalias = st.checkbox(\"Detectar anomalías\", value=False, key=\"toggle_anomalias\")\n",
    "    \n",
    "    threshold = 1.5\n",
    "    if mostrar_anomalias:\n",
    "        threshold = st.slider(\n",
    "            \"Sensibilidad de detección\",\n",
    "            min_value=1.0,\n",
    "            max_value=3.0,\n",
    "            value=1.5,\n",
    "            step=0.1,\n",
    "            help=\"Valores más bajos detectan más anomalías. 1.5=moderado, 2.0=estricto\",\n",
    "            key=\"threshold_slider\"\n",
    "        )\n",
    "\n",
    "# ---------- KPIs ----------\n",
    "st.subheader(\"Indicadores\")\n",
    "# Total y promedio mensual (idéntico a tu lógica actual)\n",
    "total = len(df_f)\n",
    "prom  = df_f[\"fecha_mes\"].value_counts().mean() if df_f[\"fecha_mes\"].notna().any() else float(\"nan\")\n",
    "\n",
    "# --- Variación robusta: escoger par de años con meses en común y base > 0 ---\n",
    "anios_con_datos = sorted(df_f[\"anio\"].dropna().unique().astype(int).tolist())\n",
    "\n",
    "def _yoy_variation_robusta(d: pd.DataFrame, meses_sel: list[int] | None):\n",
    "    if d.empty or d[\"anio\"].isna().all() or d[\"mes_num\"].isna().all():\n",
    "        return None, None, None  # (var, y0, y1)\n",
    "\n",
    "    meses = list(meses_sel) if meses_sel else MESES_ORD\n",
    "\n",
    "    # Conteos por año/mes (solo meses válidos)\n",
    "    base = (\n",
    "        d[d[\"mes_num\"].isin(meses)]\n",
    "        .groupby([\"anio\", \"mes_num\"], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"tramites\"})\n",
    "    )\n",
    "    if base.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    # Mapa de meses disponibles por año\n",
    "    meses_por_anio = (\n",
    "        base.groupby(\"anio\")[\"mes_num\"]\n",
    "            .apply(lambda s: set(s.astype(int).tolist()))\n",
    "            .to_dict()\n",
    "    )\n",
    "\n",
    "    # Intentar pares (y0, y1) con intersección de meses y base > 0\n",
    "    anios = sorted(meses_por_anio.keys())\n",
    "    mejor = None  # (var, y0, y1)\n",
    "    for y1 in reversed(anios):          # priorizar el más reciente como comparado\n",
    "        for y0 in anios:                # base\n",
    "            if y0 >= y1:\n",
    "                continue\n",
    "            inter = meses_por_anio[y0] & meses_por_anio[y1]\n",
    "            if not inter:\n",
    "                continue\n",
    "\n",
    "            a = int(base[(base[\"anio\"] == y1) & (base[\"mes_num\"].isin(inter))][\"tramites\"].sum())\n",
    "            b = int(base[(base[\"anio\"] == y0) & (base[\"mes_num\"].isin(inter))][\"tramites\"].sum())\n",
    "            if b == 0:\n",
    "                continue\n",
    "\n",
    "            var = (a - b) / b * 100.0\n",
    "            mejor = (var, y0, y1)\n",
    "            break\n",
    "        if mejor:\n",
    "            break\n",
    "\n",
    "    # Si no encontramos ningún par válido, intentar y1 vs y1-1 (año inmediato anterior)\n",
    "    if not mejor and len(anios) >= 2:\n",
    "        y1 = anios[-1]\n",
    "        y0 = y1 - 1\n",
    "        if y0 in meses_por_anio:\n",
    "            inter = meses_por_anio[y0] & meses_por_anio[y1]\n",
    "            if inter:\n",
    "                a = int(base[(base[\"anio\"] == y1) & (base[\"mes_num\"].isin(inter))][\"tramites\"].sum())\n",
    "                b = int(base[(base[\"anio\"] == y0) & (base[\"mes_num\"].isin(inter))][\"tramites\"].sum())\n",
    "                if b > 0:\n",
    "                    var = (a - b) / b * 100.0\n",
    "                    mejor = (var, y0, y1)\n",
    "\n",
    "    return mejor if mejor else (None, None, None)\n",
    "\n",
    "var, y0, y1 = _yoy_variation_robusta(df_f, meses_sel)\n",
    "label_var = f\"Variación {y0}→{y1}\" if (y0 is not None and y1 is not None) else \"Variación Anual\"\n",
    "\n",
    "\n",
    "# Empaquetar para el componente\n",
    "values = KpiValues(\n",
    "    total_tramites=total,\n",
    "    promedio_mensual=0 if (isinstance(prom, float) and math.isnan(prom)) else float(prom),\n",
    "    variacion_anual_pct=var if (var is not None and not (isinstance(var, float) and math.isnan(var))) else None,\n",
    ")\n",
    "\n",
    "\n",
    "# Renderizar 3 tarjetas con emojis y formato profesional\n",
    "render_kpi_cards(\n",
    "    values,\n",
    "    labels=(\"Total Trámites\", \"Promedio Mensual\", label_var),\n",
    "    help_texts=(\n",
    "        \"Cantidad acumulada de trámites en el periodo filtrado.\",\n",
    "        \"Promedio de trámites por mes.\",\n",
    "        \"Variación respecto al periodo equivalente del año anterior.\",\n",
    "    ),\n",
    ")\n",
    "st.divider()\n",
    "\n",
    "# ---------- Serie mensual superpuesta por año ----------\n",
    "st.subheader(\"Evolución mensual por año (superpuesta)\")\n",
    "\n",
    "if df_f[\"anio\"].notna().any() and df_f[\"mes_num\"].notna().any():\n",
    "    base = (\n",
    "        df_f.groupby([\"anio\", \"mes_num\"], as_index=False)\n",
    "            .size()\n",
    "            .rename(columns={\"size\": \"tramites\"})\n",
    "    )\n",
    "    years_for_grid = sorted(base[\"anio\"].dropna().unique().astype(int).tolist())\n",
    "    months_for_grid = sorted(set(base[\"mes_num\"].dropna().astype(int)) & set(meses_sel)) if meses_sel else MESES_ORD\n",
    "    grid = pd.DataFrame(list(itertools.product(years_for_grid, months_for_grid)), columns=[\"anio\", \"mes_num\"])\n",
    "    serie = (\n",
    "        grid.merge(base, on=[\"anio\", \"mes_num\"], how=\"left\")\n",
    "            .assign(tramites=lambda d: d[\"tramites\"].fillna(0).astype(int))\n",
    "            .sort_values([\"anio\", \"mes_num\"])\n",
    "    )\n",
    "    # columna de texto de mes para tooltip (evita lambda en format)\n",
    "    serie[\"mes_nombre\"] = serie[\"mes_num\"].map(MESES_MAP)\n",
    "\n",
    "    # Detectar anomalías por año si está activado\n",
    "    if mostrar_anomalias:\n",
    "        serie[\"es_anomalia\"] = False\n",
    "        for anio in years_for_grid:\n",
    "            mask_anio = serie[\"anio\"] == anio\n",
    "            serie.loc[mask_anio, \"es_anomalia\"] = detect_peaks(\n",
    "                serie.loc[mask_anio, \"tramites\"], \n",
    "                threshold=threshold\n",
    "            )\n",
    "    \n",
    "    # Gráfico base\n",
    "    chart = (\n",
    "        alt.Chart(serie)\n",
    "           .mark_line(point=True)\n",
    "           .encode(\n",
    "               x=alt.X(\"mes_num:O\", title=\"Mes\",\n",
    "                       sort=MESES_ORD,\n",
    "                       axis=alt.Axis(labelExpr=\"['','Ene','Feb','Mar','Abr','May','Jun','Jul','Ago','Sep','Oct','Nov','Dic'][datum.value]\")),\n",
    "               y=alt.Y(\"tramites:Q\", title=\"Trámites\"),\n",
    "               color=alt.Color(\"anio:O\", title=\"Año\"),\n",
    "               tooltip=[alt.Tooltip(\"anio:O\", title=\"Año\"),\n",
    "                        alt.Tooltip(\"mes_nombre:N\", title=\"Mes\"),\n",
    "                        alt.Tooltip(\"tramites:Q\", title=\"Trámites\")]\n",
    "           )\n",
    "           .properties(height=360)\n",
    "    )\n",
    "    \n",
    "    # Capa de anomalías\n",
    "    if mostrar_anomalias:\n",
    "        anomalias = serie[serie[\"es_anomalia\"]]\n",
    "        if not anomalias.empty:\n",
    "            chart_anomalias = (\n",
    "                alt.Chart(anomalias)\n",
    "                   .mark_point(size=200, shape=\"diamond\", filled=True)\n",
    "                   .encode(\n",
    "                       x=alt.X(\"mes_num:O\"),\n",
    "                       y=alt.Y(\"tramites:Q\"),\n",
    "                       color=alt.value(\"#FF4B4B\"),\n",
    "                       tooltip=[\n",
    "                           alt.Tooltip(\"anio:O\", title=\"Año\"),\n",
    "                           alt.Tooltip(\"mes_nombre:N\", title=\"Mes\"),\n",
    "                           alt.Tooltip(\"tramites:Q\", title=\"Trámites\"),\n",
    "                           alt.Tooltip(\"es_anomalia:N\", title=\"Anomalía\")\n",
    "                       ]\n",
    "                   )\n",
    "            )\n",
    "            chart = chart + chart_anomalias\n",
    "    \n",
    "    # Línea de tendencia por año (limitada al rango de datos)\n",
    "    if mostrar_tendencia:\n",
    "        tendencias = []\n",
    "        for anio in years_for_grid:\n",
    "            datos_anio = serie[serie[\"anio\"] == anio].copy()\n",
    "            if len(datos_anio) >= 2:\n",
    "                # Calcular la regresión manualmente para controlar el rango\n",
    "                \n",
    "                \n",
    "                X = datos_anio[\"mes_num\"].values.reshape(-1, 1)\n",
    "                y = datos_anio[\"tramites\"].values\n",
    "                \n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Predecir solo para los meses que tienen datos\n",
    "                datos_anio[\"tendencia\"] = model.predict(X)\n",
    "                \n",
    "                chart_tendencia = (\n",
    "                    alt.Chart(datos_anio)\n",
    "                       .mark_line(strokeDash=[5, 5], size=2, opacity=0.6)\n",
    "                       .encode(\n",
    "                           x=alt.X(\"mes_num:O\"),\n",
    "                           y=alt.Y(\"tendencia:Q\"),\n",
    "                           color=alt.Color(\"anio:O\", legend=None)\n",
    "                       )\n",
    "                )\n",
    "                tendencias.append(chart_tendencia)\n",
    "        \n",
    "        for tend in tendencias:\n",
    "            chart = chart + tend\n",
    "    \n",
    "    st.altair_chart(chart.interactive(), use_container_width=True)\n",
    "    \n",
    "    # Mostrar resumen de anomalías si están activadas\n",
    "    if mostrar_anomalias and \"es_anomalia\" in serie.columns:\n",
    "        num_anomalias = serie[\"es_anomalia\"].sum()\n",
    "        if num_anomalias > 0:\n",
    "            st.info(f\"Se detectaron **{num_anomalias}** anomalías con threshold={threshold}\")\n",
    "        else:\n",
    "            st.success(f\"✅ No se detectaron anomalías con threshold={threshold}\")\n",
    "else:\n",
    "    st.info(\"No hay datos temporales para graficar.\")\n",
    "\n",
    "st.divider()\n",
    "\n",
    "# ---------- Mapa ----------\n",
    "st.subheader(\"Distribución geográfica\")\n",
    "\n",
    "coords_mask = df_f[\"coords_validas\"] if \"coords_validas\" in df_f.columns else pd.Series(False, index=df_f.index)\n",
    "geo = (\n",
    "    df_f[coords_mask]\n",
    "      .dropna(subset=[\"lat\", \"lon\"])\n",
    "      .groupby([\"departamento\", \"municipio\", \"lat\", \"lon\"], as_index=False)\n",
    "      .size()\n",
    "      .rename(columns={\"size\": \"tramites\"})\n",
    ")\n",
    "\n",
    "if geo.empty:\n",
    "    st.info(\"No hay coordenadas válidas para este filtro.\")\n",
    "else:\n",
    "    geo[\"radius\"] = (geo[\"tramites\"] * 30).clip(lower=2000).astype(float)\n",
    "    geo[\"lat\"] = geo[\"lat\"].astype(float)\n",
    "    geo[\"lon\"] = geo[\"lon\"].astype(float)\n",
    "\n",
    "    view = pdk.ViewState(latitude=4.570868, longitude=-74.297333, zoom=4.8, pitch=0, bearing=0)\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        data=geo,\n",
    "        get_position='[lon, lat]',\n",
    "        get_radius='radius',\n",
    "        get_fill_color='[0, 180, 255, 200]',\n",
    "        get_line_color='[255, 255, 255, 220]',\n",
    "        stroked=True,\n",
    "        line_width_min_pixels=1,\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=120,\n",
    "        pickable=True,\n",
    "        auto_highlight=True,\n",
    "    )\n",
    "    tooltip = {\"text\": \"Depto: {departamento}\\nMunicipio: {municipio}\\nTrámites: {tramites}\"}\n",
    "    st.pydeck_chart(pdk.Deck(layers=[layer], initial_view_state=view, tooltip=tooltip))\n",
    "\n",
    "# ---------- Tabla resumen ----------\n",
    "with st.expander(\"Tabla por año/mes\"):\n",
    "    if df_f[\"anio\"].notna().any() and df_f[\"mes_num\"].notna().any():\n",
    "        tabla = (\n",
    "            df_f.groupby([\"anio\", \"mes_num\"], as_index=False)\n",
    "                .size()\n",
    "                .rename(columns={\"size\": \"tramites\", \"mes_num\": \"mes\"})\n",
    "                .sort_values([\"anio\", \"mes\"])\n",
    "        )\n",
    "        st.dataframe(tabla, use_container_width=True, hide_index=True)\n",
    "    else:\n",
    "        st.write(\"Sin datos temporales para mostrar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run dashboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhEOiG2JRw3z",
    "outputId": "393c0ca0-98e3-4484-fd28-03078800b61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.75.23.164\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://little-snails-learn.loca.lt\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
